# -*- coding: utf-8 -*-
"""
ğŸ† AI CUP Cardiac Segmentation â€” Single SwinUNETR + Light TTA (Softmax Averaging)
âœ… ç­–ç•¥ï¼šå–®æ¨¡å‹ SwinUNETRï¼Œä½¿ç”¨ TTA ç¿»è½‰ï¼Œåœ¨ logits ç©ºé–“åè½‰å¾Œï¼ŒSoftmax å¹³å‡æ¦‚ç‡åœ–ã€‚
âœ… ä¿è­‰ç¶­åº¦ç©©å®šï¼Œæœ€çµ‚è¼¸å‡º zip å¯ç›´æ¥ä¸Šå‚³ã€‚
"""

import os, glob, zipfile, copy
import numpy as np
from tqdm import tqdm
from datetime import datetime
import torch
import torch.nn.functional as F
from monai.data import Dataset, DataLoader, decollate_batch, MetaTensor
from monai.networks.nets import SwinUNETR
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,
    ScaleIntensityRanged, EnsureTyped, Invertd, AsDiscrete
)
from monai.inferers import sliding_window_inference
from monai.transforms.utils import convert_to_tensor # å¼•å…¥ç”¨æ–¼è™•ç† Argmax çµæœ

# ================== åŸºæœ¬è¨­å®š ==================
workspace_dir = os.getcwd()
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") # å¢åŠ ç§’ï¼Œç¢ºä¿å”¯ä¸€æ€§
model_path = r"C:\Users\aclab_public\Desktop\aicup1\CardiacSegV2\exps\exps\unetrpp\chgh\tune_results\AICUP_training\best_model.pth"
test_dir = r"C:\Users\aclab_public\Downloads\aicup_result"
output_dir = rf"C:\Users\aclab_public\Downloads\aicup_pred_output_SwinUNETR_TTA_{timestamp}"
zip_name= f"result_TTA_{timestamp}.zip"

os.makedirs(output_dir, exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… ä½¿ç”¨è£ç½®: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")


# ================== æ¨¡å‹è¨­å®š & è¼‰å…¥ ==================
num_classes = 4
roi_size = (128, 128, 96)
spacing = (0.7, 0.7, 0.7)
a_min, a_max = -75, 450
sw_batch_size = 1
overlap = 0.25

model = SwinUNETR(
    img_size=roi_size,
    in_channels=1,
    out_channels=num_classes,
    feature_size=48,
    use_checkpoint=False
).to(device)

try:
    ckpt = torch.load(model_path, map_location=device, weights_only=True)
    if isinstance(ckpt, dict) and "state_dict" in ckpt:
        model.load_state_dict(ckpt["state_dict"], strict=False)
    else:
        model.load_state_dict(ckpt, strict=False)
    model.eval()
    print(f"ğŸ’¾ å·²è¼‰å…¥æ¨¡å‹æ¬Šé‡: {os.path.basename(model_path)}")
except Exception as e:
    print(f"ğŸ›‘ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    exit()

# ================== TTA å®šç¾© (ç¿»è½‰) ==================
# é€™è£¡ä½¿ç”¨ 4 çµ„åˆ (ç„¡ç¿»è½‰, Dè»¸, Hè»¸, Wè»¸)
def tta_flips(img):
    # img é æœŸ shape: (B, C, D, H, W)
    return [
        (img, lambda x: x), # 1. ç„¡ç¿»è½‰
        (torch.flip(img, dims=[-3]), lambda x: torch.flip(x, dims=[-3])), # 2. D (Z) è»¸
        (torch.flip(img, dims=[-2]), lambda x: torch.flip(x, dims=[-2])), # 3. H (Y) è»¸
        (torch.flip(img, dims=[-1]), lambda x: torch.flip(x, dims=[-1])), # 4. W (X) è»¸
    ]


# ================== æ¸¬è©¦é›†è½‰æ› & Post-processing ==================
test_files = sorted(glob.glob(os.path.join(test_dir, "*.nii.gz")))
data_dicts = [{"image": f} for f in test_files]

# âš ï¸ èˆ‡è¨“ç·´ä¸€è‡´
test_transforms = Compose([
    LoadImaged(keys=["image"]),
    EnsureChannelFirstd(keys=["image"]),
    Orientationd(keys=["image"], axcodes="RAS"),
    Spacingd(keys=["image"], pixdim=spacing, mode=("bilinear",)),
    ScaleIntensityRanged(keys=["image"], a_min=a_min, a_max=a_max, b_min=0.0, b_max=1.0, clip=True),
    EnsureTyped(keys=["image"], track_meta=True),
])

test_ds = Dataset(data=data_dicts, transform=test_transforms)
test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)

post_pred_argmax = AsDiscrete(argmax=True)

inverter = Invertd(
    keys="pred",
    transform=test_transforms,
    orig_keys="image",
    meta_keys="pred_meta_dict",
    orig_meta_keys="image_meta_dict",
    nearest_interp=True, # Label Map é‚„åŸå¿…é ˆä½¿ç”¨æœ€è¿‘é„°æ’å€¼
    to_tensor=False,
)

# é¿å…ä½¿ç”¨ SaveImaged é¡ï¼Œç›´æ¥æ‰‹å‹•å­˜æª”ï¼Œç¢ºä¿ shape/meta åš´æ ¼æ§åˆ¶
def save_nifti(data, filename, output_dir):
    from monai.data.nifti_writer import write_nifti
    
    pred_data = data["pred"]
    meta = data["pred_meta_dict"]
    
    # ç¢ºä¿ affine çŸ©é™£æ­£ç¢º
    meta_affine = meta["affine"][0] if isinstance(meta["affine"], list) else meta["affine"]
    if meta_affine.ndim != 2 or meta_affine.shape != (4, 4):
        meta_affine = np.eye(4) # Fallback to identity matrix
        
    # ç¢ºä¿ pred_data æ˜¯ 3D (D, H, W) ä¸” dtype=uint8
    pred_3d = pred_data.squeeze().astype(np.uint8)
    
    # ç¢ºä¿æœ€çµ‚ shape å°é½Š (é€™æ˜¯ç‚ºäº†è§£æ±ºä½ ä¹‹å‰çš„ mismatch å•é¡Œ)
    orig_shape_meta = np.array(meta["spatial_shape"]).flatten()
    if orig_shape_meta.size == 4:
        orig_shape = orig_shape_meta[1:] # å¿½ç•¥ Channel ç¶­åº¦ C, D, H, W
    elif orig_shape_meta.size == 3:
        orig_shape = orig_shape_meta
    else:
        # å¦‚æœ Meta Data ç•°å¸¸ï¼Œç™¼å‡ºè­¦å‘Šä½†ä¸çµ‚æ­¢ï¼Œä½¿ç”¨ç•¶å‰ Shape
        orig_shape = pred_3d.shape
        print(f"âš ï¸ {filename} Meta Shape ç•°å¸¸ ({orig_shape_meta})ï¼Œä½¿ç”¨ç•¶å‰ pred shape: {orig_shape}")

    if pred_3d.shape != tuple(orig_shape):
        print(f"âš ï¸ Shape mismatch {filename}: pred={pred_3d.shape} vs orig={tuple(orig_shape)}")
        
        diff = np.array(orig_shape) - np.array(pred_3d.shape)
        pad_list = []
        crop_slices = [slice(None)] * 3
        
        for i in range(3):
            if diff[i] < 0: # Crop (pred_shape > orig_shape)
                crop_slices[i] = slice(0, orig_shape[i])
            elif diff[i] > 0: # Pad (pred_shape < orig_shape)
                pad_list.extend([0, diff[i]]) # (W, H, D)
        
        # åŸ·è¡Œ Pad (Label 0)
        if pad_list:
            pred_3d = F.pad(torch.from_numpy(pred_3d).unsqueeze(0).unsqueeze(0), 
                            tuple(pad_list[::-1]), "constant", 0).squeeze().numpy()
        
        # åŸ·è¡Œ Crop
        if any(s != slice(None) for s in crop_slices):
            pred_3d = pred_3d[crop_slices[0], crop_slices[1], crop_slices[2]]

        final_shape = pred_3d.shape
        print(f"ğŸ”§ {filename} å·²ä¿®æ­£ç‚º {final_shape}")
        
        if final_shape != tuple(orig_shape):
            raise ValueError(f"æœ€çµ‚ Shape ç„¡æ³•å°é½Š (Final {final_shape} vs Orig {tuple(orig_shape)})")

    
    # å¯«å…¥ NIfTI æª”æ¡ˆ
    output_path = os.path.join(output_dir, os.path.basename(filename))
    write_nifti(
        data=pred_3d,
        file_name=output_path,
        affine=meta_affine,
        dtype=np.uint8
    )
    print(f"âœ… {os.path.basename(filename)} å„²å­˜å®Œæˆï¼Œæœ€çµ‚ shape={pred_3d.shape}")


# ================== TTA æ¨è«–æ ¸å¿ƒé‚è¼¯ ==================
print(f"ğŸ§  é–‹å§‹å–®æ¨¡å‹ + TTA æ¨è«– {len(test_files)} ç­†æ¸¬è©¦å½±åƒ...")

with torch.no_grad(), torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):
    for batch in tqdm(test_loader):
        img = batch["image"].to(device) # (1, 1, D_norm, H_norm, W_norm)
        meta = copy.deepcopy(batch["image_meta_dict"])
        fname = os.path.basename(str(meta.get("filename_or_obj")[0]))
        all_preds_prob = [] # å„²å­˜ Softmax æ©Ÿç‡çµæœ

        # ---- TTA + Inference (Softmax å¹³å‡) ----
        for aug_img, inv_fn in tta_flips(img):
            # 1. Inference è¼¸å‡º logits
            logits = sliding_window_inference(aug_img, roi_size, sw_batch_size, model, overlap=overlap, mode="gaussian")
            
            # 2. TTA åè½‰ (Logits ç©ºé–“)
            logits_inv = inv_fn(logits)
            
            # 3. Softmax è½‰ç‚ºæ©Ÿç‡åœ–
            out_prob = F.softmax(logits_inv, dim=1)
            all_preds_prob.append(out_prob.cpu())

        # Ensemble: Softmax æ©Ÿç‡å¹³å‡ (é æœŸ shape: 1, C, D_norm, H_norm, W_norm)
        avg_prob = torch.mean(torch.stack(all_preds_prob), dim=0) 

        # 4. Argmax è½‰ç‚º Label Map (4D: 1, D_norm, H_norm, W_norm)
        pred_label_map_4d = torch.argmax(avg_prob, dim=1, keepdim=False).to(torch.long)
        
        # 5. æº–å‚™ Invertd
        # ç‚ºäº† Invertdï¼Œéœ€è¦ 5D (1, 1, D_norm, H_norm, W_norm) MetaTensor
        pred_label_map_5d = pred_label_map_4d.unsqueeze(1) 
        
        # 6. åŒ…è£ MetaTensor
        single = decollate_batch(batch)[0]
        single["pred"] = MetaTensor(pred_label_map_5d.cpu(), meta=meta)
        single["pred_meta_dict"] = single["image_meta_dict"]

        # 7. Invertd é‚„åŸåŸå§‹ spacing / shape (åˆ° numpy ç©ºé–“)
        single = inverter(single)
        
        # 8. Shape æª¢æŸ¥èˆ‡ä¿®æ­£ (ä½¿ç”¨å¼·åŒ–çš„ save å‡½æ•¸)
        save_nifti(single, fname, output_dir)


# ================== æ‰“åŒ… zip ==================
print("\n" + "="*50)
zip_path = os.path.join(os.path.dirname(output_dir), zip_name)
print(f"ğŸ“¦ é–‹å§‹æ‰“åŒ…è‡³ ZIPï¼š{zip_path}")
try:
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
        # éè¿´æœå°‹æ‰€æœ‰ .nii.gz
        for f in sorted(glob.glob(os.path.join(output_dir, "**", "*.nii.gz"), recursive=True)):
            zipf.write(f, os.path.basename(f))

    print(f"âœ… å·²å»ºç«‹ä¸Šå‚³æª”æ¡ˆ: {zip_path}")
    print("ğŸ¯ é€™ä»½ zip å¯ç›´æ¥ä¸Šå‚³è‡³ AI CUP Leaderboard è©•åˆ†ç³»çµ±")
except Exception as e:
    print(f"âŒ ZIP æ‰“åŒ…å¤±æ•—: {e}")