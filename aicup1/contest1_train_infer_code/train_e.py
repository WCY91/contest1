# -*- coding: utf-8 -*-
import os, json, random, math, numpy as np
from datetime import datetime

import torch
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR, ReduceLROnPlateau

from monai.data import CacheDataset, list_data_collate, decollate_batch
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd,
    ScaleIntensityRanged, CropForegroundd, RandFlipd, RandAffined,
    RandCropByPosNegLabeld, EnsureTyped, ToTensord, AsDiscrete,
    RandGaussianNoised, RandBiasFieldd, RandAdjustContrastd
)
from monai.losses import DiceCELoss
from monai.metrics import DiceMetric, MeanIoU
from monai.inferers import sliding_window_inference
from monai.networks.nets import SwinUNETR


# ---------------- Utils ----------------
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def param_groups_weight_decay(model, wd, skip_list=('bias', 'norm', 'bn', 'ln', 'gn', 'embedding')):
    decay, no_decay = [], []
    for name, p in model.named_parameters():
        if not p.requires_grad:
            continue
        if p.ndim == 1 or any(k in name.lower() for k in skip_list):
            no_decay.append(p)
        else:
            decay.append(p)
    return [
        {'params': decay, 'weight_decay': wd},
        {'params': no_decay, 'weight_decay': 0.0},
    ]


class ModelEMA:
    """Exponential Moving Average of model weights for more stable eval."""
    def __init__(self, model, decay=0.999):
        self.ema = type(model)(
            img_size=model.img_size, in_channels=1,
            out_channels=model.out_channels, feature_size=model.feature_size,
            use_checkpoint=getattr(model, "use_checkpoint", False)
        ).to(next(model.parameters()).device)
        self.ema.load_state_dict(model.state_dict())
        self.decay = decay
        for p in self.ema.parameters():
            p.requires_grad_(False)

    @torch.no_grad()
    def update(self, model):
        d = self.decay
        msd = model.state_dict()
        for k, v in self.ema.state_dict().items():
            if v.dtype.is_floating_point:
                v.copy_(v * d + msd[k] * (1.0 - d))


# è¼•é‡ TTAï¼ˆé©—è­‰ç”¨ï¼‰
TTA_FLIPS_VAL = [(), (2,), (3,), (4,)]  # è¨“ç·´éç¨‹ç”¨4çµ„ï¼Œçœæ™‚é–“

def infer_with_tta(images, roi_size, sw_bs, model, flips):
    logits_sum = None
    for dims in flips:
        x = images
        if dims: x = torch.flip(x, dims=dims)
        logits = sliding_window_inference(
            x, roi_size, sw_bs, model, mode="gaussian", overlap=0.65
        )
        if dims: logits = torch.flip(logits, dims=dims)
        logits_sum = logits if logits_sum is None else (logits_sum + logits)
    return logits_sum / float(len(flips))


def main():
    set_seed(42)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è£ç½®: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")

    # ---------------- CONFIG ----------------
    workspace_dir = os.getcwd()
    data_name = "chgh"
    exp_name = "AICUP_training"

    data_json = os.path.join(workspace_dir, "exps", "data_dicts", data_name, f"{exp_name}.json")
    run_dir = os.path.join(workspace_dir, "exps", "exps", "unetrpp", data_name, "tune_results", exp_name)
    os.makedirs(run_dir, exist_ok=True)

    cfg = {
        "a_min": -102, "a_max": 423,
        "spacing": (0.7, 0.7, 0.8),
        "roi_size": (128, 128, 96),
        "batch_size": 1, "val_batch_size": 1,
        "num_classes": 4, "feature_size": 48,
        "use_checkpoint": False, "use_amp": True,
        "lr": 5e-4, "weight_decay": 2e-4,
        "max_epochs": 110,             # æ‹‰é•·å°¾å·´
        "val_every": 1,
        "max_early_stop_count": 15,    # çµ¦é™LRå¾Œåå½ˆç©ºé–“
        "ema_decay": 0.999
    }

    # ---------------- LOAD DATA ----------------
    print(f"ğŸ“‚ è¼‰å…¥è³‡æ–™æè¿°æª”: {data_json}")
    with open(data_json, "r") as f:
        d = json.load(f)
    train_files, val_files = d["train"], d["val"]
    print(f"ğŸ“¦ è¨“ç·´æ¨£æœ¬æ•¸: {len(train_files)} | é©—è­‰æ¨£æœ¬æ•¸: {len(val_files)}")

    # é‡å° class3 ç¨€æœ‰æ¨£æœ¬å†åŠ æ¬Šï¼ˆä½ çš„æ¸…å–®ï¼‰
    rare_cls_ids = ["0001","0012","0013","0018","0032","0033","0036","0037","0047","0048"]
    rare_cls_files = [f for f in train_files if any(rid in f["label"] for rid in rare_cls_ids)]
    train_files = rare_cls_files * 3 + train_files
    print(f"âš–ï¸ å¼·åŒ– class3 æ¨£æœ¬æ•¸: {len(rare_cls_files)} ç­† * 3")

    # --- Transform ---
    train_tfms = Compose([
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys=["image", "label"]),
        Spacingd(keys=["image", "label"], pixdim=cfg["spacing"], mode=("bilinear", "nearest")),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        ScaleIntensityRanged(keys=["image"], a_min=cfg["a_min"], a_max=cfg["a_max"],
                             b_min=0.0, b_max=1.0, clip=True),
        CropForegroundd(keys=["image", "label"], source_key="image"),
        # â˜…æ›´ç©©å®šçš„å‰æ™¯æŠ½æ¨£
        RandCropByPosNegLabeld(keys=["image", "label"], label_key="label",
                               spatial_size=cfg["roi_size"], pos=1, neg=1, num_samples=2),
        # å¹¾ä½•èˆ‡å¼·åŒ–å°æ¯”/å™ªè²ï¼ˆå°å¿ƒåˆ¥å¤ªå¤§ï¼‰
        RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=[0,1,2]),
        RandAffined(keys=["image", "label"], prob=0.15,
                    rotate_range=(0.05,0.05,0.05), scale_range=(0.1,0.1,0.1),
                    mode=("bilinear","nearest")),
        RandGaussianNoised(keys=["image"], prob=0.1, mean=0.0, std=0.05),
        RandBiasFieldd(keys=["image"], prob=0.1, coeff_range=(0.0, 0.3)),
        RandAdjustContrastd(keys=["image"], prob=0.1, gamma=(0.7,1.5)),
        EnsureTyped(keys=["image", "label"]), ToTensord(keys=["image", "label"]),
    ])

    val_tfms = Compose([
        LoadImaged(keys=["image", "label"]),
        EnsureChannelFirstd(keys=["image", "label"]),
        Spacingd(keys=["image", "label"], pixdim=cfg["spacing"], mode=("bilinear", "nearest")),
        Orientationd(keys=["image", "label"], axcodes="RAS"),
        ScaleIntensityRanged(keys=["image"], a_min=cfg["a_min"], a_max=cfg["a_max"],
                             b_min=0.0, b_max=1.0, clip=True),
        EnsureTyped(keys=["image", "label"]), ToTensord(keys=["image", "label"]),
    ])

    print("ğŸ§  å»ºç«‹ Dataset ...")
    train_ds = CacheDataset(train_files, train_tfms, cache_rate=0.0, num_workers=4)
    val_ds = CacheDataset(val_files, val_tfms, cache_rate=0.0, num_workers=2)
    train_loader = DataLoader(train_ds, batch_size=cfg["batch_size"], shuffle=True, collate_fn=list_data_collate)
    val_loader = DataLoader(val_ds, batch_size=cfg["val_batch_size"], shuffle=False, collate_fn=list_data_collate)

    # ---------------- MODEL ----------------
    print("âš™ï¸ åˆå§‹åŒ– SwinUNETR æ¨¡å‹ä¸­...")
    model = SwinUNETR(
        img_size=cfg["roi_size"],
        in_channels=1, out_channels=cfg["num_classes"],
        feature_size=cfg["feature_size"], use_checkpoint=cfg["use_checkpoint"]
    ).to(device)
    print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ!")

    # ---------------- LOSS / OPT / EMA ----------------
    # æ›´é‡ç–Šçš„æ¬Šé‡ç•¥é«˜ï¼Œå¹«åŠ© Dice/IoU
    loss_fn = DiceCELoss(to_onehot_y=True, softmax=True, lambda_dice=1.0, lambda_ce=0.5)

    optimizer = torch.optim.AdamW(
        param_groups_weight_decay(model, wd=cfg["weight_decay"]),
        lr=cfg["lr"]
    )
    scaler = GradScaler(enabled=cfg["use_amp"])

    ema = ModelEMA(model, decay=cfg["ema_decay"])

    dice_metric = DiceMetric(include_background=True, reduction="mean", get_not_nans=False)
    iou_metric = MeanIoU(include_background=True, reduction="mean")

    def lr_lambda(epoch): return min(1.0, float(epoch + 1) / 3)
    warmup_scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)
    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=cfg["max_epochs"] - 3, eta_min=1e-6)
    plateau_scheduler = ReduceLROnPlateau(optimizer, mode="max", factor=0.5, patience=3, verbose=True, min_lr=1e-6)

    best_score = -1.0
    no_improve = 0
    log_file = os.path.join(run_dir, f"train_log_{datetime.now().strftime('%m%d_%H%M')}.txt")

    print(f"ğŸš€ é–‹å§‹è¨“ç·´ | epochs={cfg['max_epochs']} | base_lr={cfg['lr']} | wd={cfg['weight_decay']}")
    print("="*80)

    # ---------------- TRAIN LOOP ----------------
    for epoch in range(cfg["max_epochs"]):
        model.train()
        running_loss = 0.0
        phase = "Warmup" if epoch < 3 else "Train"
        print(f"\nğŸŒ€ Epoch {epoch+1}/{cfg['max_epochs']} [{phase}]")

        for i, batch in enumerate(train_loader):
            img, lab = batch["image"].to(device), batch["label"].to(device)
            optimizer.zero_grad(set_to_none=True)

            with autocast(enabled=cfg["use_amp"]):
                out = model(img)
                loss = loss_fn(out, lab)

            scaler.scale(loss).backward()
            # æ¢¯åº¦è£å‰ª + AMP æ­£ç¢ºé †åº
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()

            # EMA è·Ÿéš¨
            ema.update(model)

            if (i+1) % 5 == 0:
                print(f"   ğŸ”¹ Batch {i+1}/{len(train_loader)} | Loss={loss.item():.4f}")

        if epoch < 3: warmup_scheduler.step()
        else: cosine_scheduler.step()

        avg_loss = running_loss / max(1, len(train_loader))
        print(f"ğŸ“‰ å¹³å‡è¨“ç·´ Loss={avg_loss:.4f} | LR={optimizer.param_groups[0]['lr']:.6f}")

        # ---------------- VALIDATION ----------------
        if (epoch + 1) % cfg["val_every"] == 0:
            print("ğŸ§ª é©—è­‰ä¸­ï¼ˆEMAæ¬Šé‡ + 4xTTAï¼‰...")
            model.eval()
            dice_metric.reset()
            per_class_iou = []

            # ç”¨ EMA æ¬Šé‡åšé©—è­‰
            bak = {k: v.clone() for k, v in model.state_dict().items()}
            model.load_state_dict(ema.ema.state_dict(), strict=True)

            post_pred = AsDiscrete(argmax=True, to_onehot=cfg["num_classes"])
            post_label = AsDiscrete(to_onehot=cfg["num_classes"])

            with torch.no_grad():
                for val_data in val_loader:
                    img, lab = val_data["image"].to(device), val_data["label"].to(device)
                    with autocast(enabled=cfg["use_amp"]):
                        logits = infer_with_tta(img, cfg["roi_size"], 2, model, TTA_FLIPS_VAL)
                        pred_soft = torch.softmax(logits, dim=1)

                    val_outputs = [post_pred(i) for i in decollate_batch(pred_soft)]
                    val_labels  = [post_label(i) for i in decollate_batch(lab)]
                    dice_metric(y_pred=val_outputs, y=val_labels)

                    pred_arg = pred_soft.argmax(dim=1)
                    ious = []
                    for c in range(cfg["num_classes"]):
                        inter = ((pred_arg == c) & (lab.squeeze(1) == c)).sum().item()
                        union = ((pred_arg == c) | (lab.squeeze(1) == c)).sum().item()
                        if union > 0:
                            ious.append(inter / union)
                    if ious:
                        per_class_iou.append(np.mean(ious))

            dice_vals = dice_metric.aggregate().cpu()
            mean_dice = dice_vals.mean().item()
            mean_iou = float(np.mean(per_class_iou)) if per_class_iou else 0.0
            score = (mean_dice + mean_iou) / 2

            # é‚„åŸåŸæ¬Šé‡ï¼Œç¹¼çºŒè¨“ç·´
            model.load_state_dict(bak, strict=True)

            msg = f"Epoch [{epoch+1}/{cfg['max_epochs']}], Loss={avg_loss:.4f}, Dice={mean_dice:.4f}, IoU={mean_iou:.4f}, Score={score:.4f}"
            print("ğŸ“Š", msg)
            dice_str = " | ".join([f"class{i}={v:.4f}" for i, v in enumerate(dice_vals.tolist())])
            print(f"ğŸ¯ æ¯é¡ Dice: {dice_str} | å¹³å‡ Dice={mean_dice:.4f}")

            with open(log_file, "a") as f:
                f.write(msg + "\n")

            # åœæ»¯å°±é™LR
            plateau_scheduler.step(score)

            # å­˜æœ€ä½³ï¼ˆä»¥ Scoreï¼‰
            if score > best_score:
                best_score = score
                no_improve = 0
                save_path = os.path.join(run_dir, f"best_model_{best_score:.4f}.pth")
                torch.save(ema.ema.state_dict(), save_path)  # â˜…ä¿å­˜EMAæ¬Šé‡ç‚ºbest
                print(f"ğŸ’¾ å„²å­˜æœ€ä½³æ¨¡å‹(EMA) -> {save_path}")
            else:
                no_improve += 1
                print(f"âš ï¸ æœªæ”¹å–„æ¬¡æ•¸: {no_improve}/{cfg['max_early_stop_count']}")
                if no_improve >= cfg["max_early_stop_count"]:
                    print("ğŸ›‘ EarlyStopping è§¸ç™¼ï¼ŒçµæŸè¨“ç·´ã€‚")
                    break

    print("="*80)
    print(f"âœ… è¨“ç·´çµæŸ | æœ€ä½³ç¶œåˆåˆ†æ•¸: {best_score:.4f}")


if __name__ == "__main__":
    import torch.multiprocessing as mp
    mp.freeze_support()
    main()
