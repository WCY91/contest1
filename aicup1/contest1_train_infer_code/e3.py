# -*- coding: utf-8 -*-
"""
âœ… Final Inference Script for AI CUP Cardiac Segmentation - Dual Model Weighted Soft Ensemble (Optimized)
- å¯¦ç¾åœ¨åŸå§‹ç©ºé–“ä¸Šå°å…©å€‹æ¨¡å‹çš„é æ¸¬é€²è¡Œ Softmax åŠ æ¬Šå¹³å‡
- æ•´åˆ TTA (ç¿»è½‰å¢å¼·)
- æ•´åˆå¾Œè™•ç† (LCC, å°ç‰©é«”ç§»é™¤)
"""

import os, glob, zipfile, sys
import numpy as np
from tqdm import tqdm
from datetime import datetime
from typing import Dict, Any, List

import torch
import torch.nn.functional as F
from monai.data import Dataset, DataLoader, decollate_batch
from monai.networks.nets import SwinUNETR, SegResNet
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,
    ScaleIntensityRanged, EnsureTyped, AsDiscrete, Invertd, SaveImaged
)
from monai.inferers import sliding_window_inference
from monai.utils import PostFix

# === å¼•å…¥ Scipy/Skimage é€²è¡Œå¾Œè™•ç† (å¦‚æœæ²’æœ‰å®‰è£ï¼Œè«‹ä½¿ç”¨ pip install scipy scikit-image) ===
try:
    from scipy.ndimage import gaussian_filter, label
    from skimage.morphology import remove_small_objects
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šç¼ºå°‘ Scipy æˆ– Scikit-Imageã€‚Gaussian Smoothing å’Œ Post-processing å°‡è¢«è·³éã€‚")
    gaussian_filter = None
    label = None
    remove_small_objects = None
# =========================================================================================


# ================== æ ¸å¿ƒé–‹é—œèˆ‡è¨­å®š ==================
timestamp = datetime.now().strftime("%Y%m%d_%H%M")

# âš ï¸ è«‹è‡ªè¡Œä¿®æ”¹ç‚ºæ‚¨çš„æ¨¡å‹èˆ‡è³‡æ–™è·¯å¾‘
swinunetr_model_path = r"C:\Users\aclab_public\Desktop\aicup1\CardiacSegV2\exps\exps\unetrpp\chgh\tune_results\AICUP_training\best_model_finetune_v2.pth"
segresnet_model_path = r"C:\Users\aclab_public\Downloads\best_model_segresnet.pth"
test_dir    = r"C:\Users\aclab_public\Downloads\aicup_result"
output_dir = rf"C:\Users\aclab_public\Downloads\aicup_pred_weighted_soft_ensemble_{timestamp}"
zip_name    = f"result_weighted_soft_ensemble_{timestamp}.zip"

# --- ğŸ¯ èåˆ/å¢å¼·é–‹é—œ ---
ENABLE_TTA = True               # æ–¹å‘äºŒï¼šæ˜¯å¦å•Ÿç”¨ TTA (RL, AP, SI ç¿»è½‰)
GAUSSIAN_SIGMA = 1.0            # æ–¹å‘äº”ï¼šLogits Smoothing (0.0 ç¦ç”¨)
ENABLE_POST_PROCESSING = True   # æ–¹å‘ä¸‰ï¼šæ˜¯å¦å•Ÿç”¨å¾Œè™•ç† (LCC + å°ç‰©é«”ç§»é™¤)
CRF_ENABLE = False              # æ–¹å‘å…­ï¼š3D CRF (ç›®å‰æœªå¯¦ä½œï¼Œåƒ…ç‚ºé–‹é—œ)

# --- ğŸ¯ æ¬Šé‡è¨­å®š (Soft Ensemble) ---
WEIGHT_SWINUNETR = 1
WEIGHT_SEGRESNET = 2

# ================== æ¨¡å‹å…±åŒè¨­å®š ==================
num_classes = 4
sw_batch_size = 1
overlap = 0.25

# ================== æ¨¡å‹å„è‡ªè¨­å®š ==================
swinunetr_cfg = {"spacing": (0.7, 0.7, 0.7), "roi_size": (128, 128, 96), "a_min": -75, "a_max": 450}
segresnet_cfg = {"spacing": (0.7, 0.7, 0.8), "roi_size": (128, 128, 96), "a_min": -75, "a_max": 450}

# ====== è£ç½®èˆ‡åˆå§‹åŒ– ======
has_cuda = torch.cuda.is_available()
device = torch.device("cuda" if has_cuda else "cpu")

def set_determinism(seed: int = 2025):
    import random
    import numpy as _np
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    random.seed(seed)
    _np.random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
def must_exist(path: str, kind: str):
    if not os.path.exists(path):
        print(f"âŒ {kind} ä¸å­˜åœ¨ï¼š{path}")
        sys.exit(1)

# ================== è¼”åŠ©å‡½æ•¸ï¼šæ¨¡å‹è¼‰å…¥èˆ‡æ¨è«– ==================
def load_swinunetr_model(model_path: str, device: torch.device) -> SwinUNETR:
    model = SwinUNETR(img_size=swinunetr_cfg["roi_size"], in_channels=1, out_channels=num_classes, feature_size=48, use_checkpoint=False).to(device)
    ckpt = torch.load(model_path, map_location=device)
    state = ckpt["state_dict"] if isinstance(ckpt, dict) and "state_dict" in ckpt else ckpt
    model.load_state_dict(state, strict=False)
    model.eval()
    return model

def load_segresnet_model(model_path: str, device: torch.device) -> SegResNet:
    model = SegResNet(
        spatial_dims=3, in_channels=1, out_channels=num_classes,
        init_filters=32, blocks_down=[1,2,2,4], blocks_up=[1,1,1], dropout_prob=0.2
    ).to(device)
    ckpt = torch.load(model_path, map_location=device)
    state = ckpt["state_dict"] if isinstance(ckpt, dict) and "state_dict" in ckpt else ckpt
    model.load_state_dict(state, strict=False)
    model.eval()
    return model

def get_transforms(cfg: Dict[str, Any], keys: List[str]) -> Compose:
    return Compose([
        LoadImaged(keys=keys), EnsureChannelFirstd(keys=keys), Orientationd(keys=keys, axcodes="RAS"),
        Spacingd(keys=keys, pixdim=cfg["spacing"], mode="bilinear"),
        ScaleIntensityRanged(keys=keys, a_min=cfg["a_min"], a_max=cfg["a_max"], b_min=0.0, b_max=1.0, clip=True),
        EnsureTyped(keys=keys, track_meta=True),
    ])

# ç¿»è½‰è»¸å‘å®šç¾© (RL=0, AP=1, SI=2)
FLIP_AXES = [(0,), (1,), (2,)] # åƒ…è€ƒæ…®å–®è»¸ç¿»è½‰

@torch.inference_mode()
def inference_and_invert(
    model: torch.nn.Module, cfg: Dict[str, Any], data_loader: DataLoader, 
    transforms: Compose, pred_key: str
) -> Dict[str, np.ndarray]:
    """åŸ·è¡Œæ¨è«– (å« TTA/Smoothing)ï¼ŒInvert å›åŸå§‹ç©ºé–“ï¼Œä¸¦å›å‚³ Softmax æ¦‚ç‡åœ– (C, D, H_orig, W_orig)"""
    inverted_probs: Dict[str, np.ndarray] = {}
    use_amp = has_cuda
    autocast_dtype = "cuda" if use_amp else "cpu"

    pbar = tqdm(data_loader, desc=f"ğŸ§  æ¨è«– {model.__class__.__name__}", leave=False)
    for batch in pbar:
        # æº–å‚™ TTA ç´¯ç©è®Šæ•¸
        accumulated_softmax = None
        tta_count = 0
        
        # å–å¾—åŸå§‹å½±åƒè³‡è¨Š (meta)
        single_original = decollate_batch(batch)[0]
        original_filename = os.path.basename(single_original["image_meta_dict"]["filename_or_obj"])
        
        # --------------------- TTA è¿´åœˆ ---------------------
        tta_list = [()] # åˆå§‹åŒ…å«åŸåœ– (ç„¡ç¿»è½‰)
        if ENABLE_TTA:
            tta_list.extend(FLIP_AXES)

        for axes in tta_list:
            img = batch["image"].to(device, non_blocking=True)
            
            # 1. æ‡‰ç”¨ç¿»è½‰ (Augmentation)
            if axes:
                img = torch.flip(img, dims=axes)

            # 2. é€²è¡Œæ¨è«–
            with torch.amp.autocast(autocast_dtype, enabled=use_amp):
                logits = sliding_window_inference(
                    img, cfg["roi_size"], sw_batch_size, model,
                    overlap=overlap, mode="gaussian"
                )
            
            # 3. Gaussian Smoothing (æ–¹å‘äº”)
            if GAUSSIAN_SIGMA > 0 and gaussian_filter is not None:
                logits_np = logits.squeeze(0).cpu().numpy()
                # å° logits (C, D, H, W) æ¯å€‹é¡åˆ¥çš„æ¦‚ç‡åœ–é€²è¡Œé«˜æ–¯å¹³æ»‘
                for c in range(logits_np.shape[0]):
                    logits_np[c] = gaussian_filter(logits_np[c], sigma=GAUSSIAN_SIGMA, order=0)
                logits = torch.from_numpy(logits_np).unsqueeze(0).to(device)


            # 4. è½‰æ›ç‚º Softmax æ¦‚ç‡
            softmax_prob = F.softmax(logits, dim=1).cpu().squeeze(0) # (C, D, H, W)
            
            # 5. åå‘ç¿»è½‰ (De-Augmentation)
            if axes:
                softmax_prob = torch.flip(softmax_prob, dims=axes)

            # 6. ç´¯ç©
            if accumulated_softmax is None:
                accumulated_softmax = softmax_prob
            else:
                accumulated_softmax += softmax_prob
            tta_count += 1
            
        # 7. TTA å¹³å‡ Softmax (åœ¨åŸåœ–è½‰æ›ç©ºé–“)
        avg_softmax = accumulated_softmax / tta_count
        
        # --------------------- Invert é‚„åŸ ---------------------
        inverter = Invertd(
            keys=pred_key, transform=transforms, orig_keys="image",
            meta_keys=f"{pred_key}_meta_dict", orig_meta_keys="image_meta_dict",
            nearest_interp=False, to_tensor=False, # Softmax æ¦‚ç‡ä½¿ç”¨ç·šæ€§/é›™ç·šæ€§æ’å€¼ (False)
        )
        
        # å°‡ Softmax æ¦‚ç‡å¼µé‡ä½œç‚ºé æ¸¬çµæœ
        single_original[pred_key] = avg_softmax 
        single_original[f"{pred_key}_meta_dict"] = single_original["image_meta_dict"]

        # é‚„åŸå›åŸå§‹ spacing & shape
        single_original = inverter(single_original)
        
        # å„²å­˜é‚„åŸå¾Œçš„ Softmax æ¦‚ç‡ (C, D, H_orig, W_orig)
        arr = single_original[pred_key]
        if not isinstance(arr, np.ndarray):
            arr = np.asarray(arr)
        
        inverted_probs[original_filename] = arr.astype(np.float32, copy=False)

    return inverted_probs


# ================== å¾Œè™•ç†è¼”åŠ©å‡½æ•¸ ==================
def apply_post_processing(mask_in: np.ndarray, num_classes: int, threshold: int = 1000) -> np.ndarray:
    """æ–¹å‘ä¸‰ï¼šå° Argmax é®ç½©æ‡‰ç”¨ LCC å’Œå°ç‰©é«”ç§»é™¤"""
    if label is None or remove_small_objects is None:
        print("âš ï¸ è­¦å‘Šï¼šå¾Œè™•ç†æœªåŸ·è¡Œï¼Œè«‹ç¢ºä¿ Scipy å’Œ Scikit-Image å·²å®‰è£ã€‚")
        return mask_in

    mask_out = mask_in.copy()
    
    # é‡å°é™¤äº†èƒŒæ™¯ (Class 0) ä»¥å¤–çš„æ¯å€‹é¡åˆ¥é€²è¡Œè™•ç†
    for c in range(1, num_classes):
        binary_mask = (mask_in == c)
        
        if not np.any(binary_mask):
            continue
            
        # 1. ç§»é™¤å°æ–¼é–¾å€¼çš„å°ç‰©é«”/å™ªé»
        # True: ç§»é™¤å°æ–¼é–¾å€¼çš„é€£é€šå€å¡Š
        cleaned_mask = remove_small_objects(binary_mask, min_size=threshold, connectivity=1)
        
        # 2. ä¿ç•™æœ€å¤§é€£é€šå€ (Largest Connected Component, LCC)
        labeled_array, num_features = label(cleaned_mask)
        
        if num_features > 0:
            # æ‰¾å‡ºæœ€å¤§é€£é€šå€çš„æ¨™ç±¤
            component_sizes = np.bincount(labeled_array.ravel())
            # è·³éèƒŒæ™¯æ¨™ç±¤ 0
            largest_component_label = np.argmax(component_sizes[1:]) + 1 
            
            # å»ºç«‹ LCC é®ç½©
            lcc_mask = (labeled_array == largest_component_label)
        else:
            lcc_mask = cleaned_mask # å¦‚æœæ¸…ç†å¾Œæ²’æœ‰é€£é€šå€ï¼Œå‰‡ç”¨æ¸…ç†å¾Œçš„çµæœ (æ‡‰ç‚ºå…¨ False)
        
        # æ›´æ–°è¼¸å‡ºé®ç½©
        mask_out[lcc_mask] = c
        # ç¢ºä¿é LCC éƒ¨åˆ†è¢«èƒŒæ™¯æˆ–å¾ŒçºŒé¡åˆ¥è¦†è“‹ï¼Œé€™è£¡ç°¡å–®ç¢ºä¿é LCC ä¸”åŸç‚º C çš„éƒ¨åˆ†è¨­å› 0
        mask_out[~lcc_mask & (mask_in == c)] = 0 
        
    return mask_out


# ================== æ ¸å¿ƒåŸ·è¡Œå€å¡Š ==================
if __name__ == '__main__':
    
    # ====== åŸ·è¡Œåˆå§‹åŒ– ======
    set_determinism()
    print(f"âœ… ä½¿ç”¨è£ç½®: {torch.cuda.get_device_name(0) if has_cuda else 'CPU'}")
    print(f"ğŸ—³ï¸ Ensemble æ¬Šé‡: SwinUNETR ({WEIGHT_SWINUNETR}), SegResNet ({WEIGHT_SEGRESNET})")
    print(f"âœ¨ TTA: {'å•Ÿç”¨' if ENABLE_TTA else 'ç¦ç”¨'}, Smoothing: Sigma={GAUSSIAN_SIGMA}, Post-processing: {'å•Ÿç”¨' if ENABLE_POST_PROCESSING else 'ç¦ç”¨'}")

    os.makedirs(output_dir, exist_ok=True)
    must_exist(swinunetr_model_path, "SwinUNETR æ¬Šé‡")
    must_exist(segresnet_model_path, "SegResNet æ¬Šé‡")
    must_exist(test_dir, "æ¸¬è©¦è³‡æ–™å¤¾")

    # ====== æ¨è«–æµç¨‹ ======
    
    # 1) è¼‰å…¥æ¨¡å‹
    print("-" * 30)
    swinunetr_model = load_swinunetr_model(swinunetr_model_path, device)
    segresnet_model = load_segresnet_model(segresnet_model_path, device)

    # 2) æº–å‚™æ¸¬è©¦è³‡æ–™
    test_files = sorted(glob.glob(os.path.join(test_dir, "*.nii.gz")))
    if len(test_files) == 0:
        print(f"âŒ åœ¨ {test_dir} æ‰¾ä¸åˆ° *.nii.gz")
        sys.exit(1)
    data_dicts = [{"image": f} for f in test_files]

    num_workers = max(os.cpu_count() // 2, 0) # è¨­ç½®ç‚º 0 ä»¥é¿å… Windows å¤šé€²ç¨‹éŒ¯èª¤
    # num_workers = 0 # âš ï¸ å¦‚æœæŒçºŒå‡ºéŒ¯ï¼Œè«‹ä½¿ç”¨é€™è¡Œ
    
    loader_cfg = dict(batch_size=1, shuffle=False, num_workers=num_workers, pin_memory=has_cuda)

    # --- SwinUNETR æ¨è«– (è¼¸å‡º Softmax æ¦‚ç‡) ---
    swinunetr_transforms = get_transforms(swinunetr_cfg, keys=["image"])
    swinunetr_ds = Dataset(data=data_dicts, transform=swinunetr_transforms)
    swinunetr_loader = DataLoader(swinunetr_ds, **loader_cfg)

    swinunetr_preds_prob = inference_and_invert(
        swinunetr_model, swinunetr_cfg, swinunetr_loader, swinunetr_transforms, pred_key="pred_swin"
    )

    # --- SegResNet æ¨è«– (è¼¸å‡º Softmax æ¦‚ç‡) ---
    segresnet_transforms = get_transforms(segresnet_cfg, keys=["image"])
    segresnet_ds = Dataset(data=data_dicts, transform=segresnet_transforms)
    segresnet_loader = DataLoader(segresnet_ds, **loader_cfg)

    segresnet_preds_prob = inference_and_invert(
        segresnet_model, segresnet_cfg, segresnet_loader, segresnet_transforms, pred_key="pred_segres"
    )

    # ================== åŠ æ¬Š Soft Ensemble èˆ‡å„²å­˜ ==================
    print("ğŸ—³ï¸ é€²è¡Œ Softmax åŠ æ¬Šå¹³å‡ Ensemble...")

    # Ensemble ç”¨çš„ DataLoader (åƒ…ç”¨æ–¼è¿­ä»£æª”åå’Œ meta data)
    final_transforms = Compose([LoadImaged(keys=["image"]), EnsureChannelFirstd(keys=["image"])])
    final_ds = Dataset(data=data_dicts, transform=final_transforms)
    final_loader = DataLoader(final_ds, **loader_cfg)

    save_pred = SaveImaged(
        keys="ensemble_pred", meta_keys="image_meta_dict", output_dir=output_dir,
        output_postfix="", output_dtype=np.uint8, resample=False, print_log=False,
    )

    saved_count = 0
    pbar_save = tqdm(final_loader, desc="ğŸ’¾ å„²å­˜åŠ æ¬Š Ensemble çµæœ")
    for batch in pbar_save:
        single = decollate_batch(batch)[0]
        original_filename = os.path.basename(single["image_meta_dict"]["filename_or_obj"])

        prob_swin  = swinunetr_preds_prob.get(original_filename)
        prob_segres= segresnet_preds_prob.get(original_filename)

        if prob_swin is None or prob_segres is None:
            raise KeyError(f"æ‰¾ä¸åˆ° {original_filename} çš„å…¶ä¸­ä¸€å€‹æ¨¡å‹æ¦‚ç‡é æ¸¬")
        
        # 1. Softmax åŠ æ¬Šå¹³å‡ (æ–¹å‘ä¸€)
        # Final_Prob = (Prob_Swin * W_Swin + Prob_SegRes * W_SegRes) / (W_Swin + W_SegRes)
        ensemble_prob = (
            (prob_swin * WEIGHT_SWINUNETR) + (prob_segres * WEIGHT_SEGRESNET)
        ) / (WEIGHT_SWINUNETR + WEIGHT_SEGRESNET)
        
        # 2. Argmax è½‰æ›ç‚ºé›¢æ•£é®ç½©
        ensemble_pred_np = np.argmax(ensemble_prob, axis=0).astype(np.uint8, copy=False)
        
        # 3. å¾Œè™•ç† (æ–¹å‘ä¸‰)
        if ENABLE_POST_PROCESSING and label is not None:
            # é‡å°æ¯å€‹é¡åˆ¥åŸ·è¡Œ LCC å’Œå°ç‰©é«”ç§»é™¤
            ensemble_pred_np = apply_post_processing(ensemble_pred_np, num_classes=num_classes, threshold=1000)

        # 4. å„²å­˜
        single["ensemble_pred"] = ensemble_pred_np
        single["image_meta_dict"][PostFix.meta_key("filename_or_obj")] = original_filename
        save_pred(single)
        saved_count += 1

    print(f"âœ… æ¨è«–èˆ‡åŠ æ¬Š Soft Ensemble å®Œæˆï¼Œæª”æ¡ˆæ•¸ï¼š{saved_count}ï¼Œè¼¸å‡ºè³‡æ–™å¤¾ï¼š{output_dir}")

    # ================== æ‰“åŒ… zip ==================
    zip_path = os.path.join(os.path.dirname(output_dir), zip_name)
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as zipf:
        nii_files = sorted(glob.glob(os.path.join(output_dir, "**", "*.nii.gz"), recursive=True))
        for f in nii_files:
            zipf.write(f, os.path.basename(f))
    print(f"ğŸ“¦ å·²å»ºç«‹ä¸Šå‚³æª”æ¡ˆ: {zip_path}ï¼ˆå…± {len(nii_files)} ä»¶ï¼‰")
    print("ğŸ¯ é€™ä»½ zip å¯ç›´æ¥ä¸Šå‚³è‡³ AI CUP Leaderboard è©•åˆ†ç³»çµ±")

    # æ¸…ç† GPU è¨˜æ†¶é«”ï¼ˆå¯é¸ï¼‰
    if has_cuda:
        torch.cuda.empty_cache()